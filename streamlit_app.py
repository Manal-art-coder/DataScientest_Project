import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.graph_objects as go
import plotly.express as px
from scipy.stats import chi2_contingency
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.preprocessing import OneHotEncoder, RobustScaler
from sklearn.impute import SimpleImputer
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier, BaggingClassifier, AdaBoostClassifier, GradientBoostingClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import recall_score, precision_score, accuracy_score, f1_score, classification_report, precision_recall_curve, PrecisionRecallDisplay,  confusion_matrix, ConfusionMatrixDisplay, roc_curve, auc
import joblib
from sklearn.utils.validation import check_is_fitted
import os

df=pd.read_csv(r"https://raw.githubusercontent.com/Manal-art-coder/DataScientest_Project/main/bank.csv")
df.head()
st.title("PrÃ©diction du succÃ¨s d'une campagne Marketing")
st.sidebar.title("Sommaire")
pages=["Contexte & enjeux", "PrÃ©sentation des donnÃ©es", "Visualisation des donnÃ©es", "PrÃ©processing", "ModÃ¨les ML", "Meilleur modÃ¨le", "Faites votre propre prÃ©diction !","Conclusion & Recommandations", "DifficultÃ©s & perspectives"]
page=st.sidebar.radio("Aller vers", pages)

if page == pages[0]: 
    # ğŸ”· Section Contexte & Enjeux
    st.write("### ğŸ“Œ Contexte & Enjeux")
    
    # Ajout d'une image d'illustration
    st.image(r"https://raw.githubusercontent.com/Manal-art-coder/DataScientest_Project/main/Screenshot 2025-02-19 111852.jpg", use_column_width=True)
    
    st.write("""
    Ce projet sâ€™inscrit dans le cadre de notre formation de **Data Analyst** avec lâ€™organisme **DataScientest**.  

    ### ğŸ¯ Objectif du projet  
    Lâ€™objectif est dâ€™analyser et prÃ©dire le succÃ¨s dâ€™une **campagne marketing bancaire** en identifiant les facteurs influenÃ§ant la souscription des clients Ã  une offre de dÃ©pÃ´t Ã  terme.  

    ### ğŸ“Š DonnÃ©es utilisÃ©es  
    - Le dataset provient de la plateforme **Kaggle**, accessible ici : [Bank Marketing Dataset](https://www.kaggle.com/datasets/janiobachmann/bank-marketing-dataset).  
    - Il contient des informations dÃ©taillÃ©es sur les clients, les interactions passÃ©es et les rÃ©sultats des campagnes marketing.  

    ### ğŸ” DÃ©marche adoptÃ©e  
    Ce **Tableau de bord interactif Streamlit** retrace toutes les Ã©tapes du projet :  
    1. Exploration et prÃ©traitement des donnÃ©es  
    2. Visualisation des variables explicatives  
    3. Mise en place et comparaison de plusieurs **modÃ¨les de Machine Learning**  
    4. SÃ©lection du modÃ¨le le plus performant  
    5. **PrÃ©diction en temps rÃ©el** sur de nouvelles donnÃ©es  

    ğŸ“¢ Ce projet permet ainsi de mieux comprendre les dynamiques des campagnes marketing et d'optimiser les stratÃ©gies commerciales ! ğŸš€
    """)

    # ğŸ”· Section Ã‰quipe du Projet
    st.write("### ğŸ‘¥ Ã‰quipe du Projet")

    # ğŸ“Œ Liste des membres de l'Ã©quipe
    team_members = [
        {"nom": "Jewa", "prenom": "Manal", "linkedin": "https://www.linkedin.com/in/manaljewa/"},
        {"nom": "Selle", "prenom": "Manon", "linkedin": "https://www.linkedin.com/in/manon-selle/"},
        {"nom": "Demeulemeester", "prenom": "Elyse", "linkedin": "https://www.linkedin.com/in/elyse-demeulemeester-aa41832b7/"},
        {"nom": "Amiel", "prenom": "Audrey", "linkedin": "https://www.linkedin.com/in/audrey-amiel/"},
        {"nom": "Legrand", "prenom": "David", "linkedin": "https://www.linkedin.com/in/lucas-morel"}
    ]

    # ğŸ“Œ Affichage des membres sur deux lignes
    col1, col2, col3 = st.columns(3)  # PremiÃ¨re ligne (3 colonnes)
    col4, col5 = st.columns(2)  # DeuxiÃ¨me ligne (2 colonnes)

    columns = [col1, col2, col3, col4, col5]

    for col, member in zip(columns, team_members):
        with col:
            st.write(f"**{member['prenom']} {member['nom']}**")
            st.markdown(f"[LinkedIn]({member['linkedin']})")  # Lien vers le profil LinkedIn

if page == pages[1]:
    # Titre principal
    st.title("PrÃ©sentation des donnÃ©es ğŸ“Š")

    # AperÃ§u du dataset
    st.subheader("AperÃ§u des premiÃ¨res lignes")
    st.write("Voici un aperÃ§u des 10 premiÃ¨res lignes du jeu de donnÃ©es :")
    st.dataframe(df.head(10))

    # Taille du dataset
    st.subheader("Taille du Dataset")
    st.write(f"**Nombre de lignes** : {df.shape[0]}")
    st.write(f"**Nombre de colonnes** : {df.shape[1]}")
    st.subheader("Types des Variables dans le Dataset")
    categorical_vars = df.select_dtypes(include=['object', 'category']).columns.tolist()
    numerical_vars = df.select_dtypes(include=['int64', 'float64']).columns.tolist()
    if st.button("Afficher les types des variables"):
        st.dataframe(df.dtypes.reset_index().rename(columns={"index": "Variable", 0: "Type"}))
    if st.button("Afficher les variables catÃ©gorielles"):
        st.write("### Variables CatÃ©gorielles")
        st.write(categorical_vars)
    if st.button("Afficher les variables numÃ©riques"):
        st.write("### Variables NumÃ©riques")
        st.write(numerical_vars)    

    # Statistiques descriptives
    st.subheader("Statistiques Descriptives")
    st.write("RÃ©sumÃ© statistique des variables numÃ©riques du dataset :")
    st.dataframe(df.describe())

    # VÃ©rification des valeurs manquantes
    st.subheader("Valeurs Manquantes")
    if st.checkbox("Afficher les valeurs manquantes ğŸ”"):
        missing_values = df.isna().sum()
        if missing_values.sum() == 0:
            st.success("Aucune valeur manquante dans le dataset ! âœ…")
        else:
            st.dataframe(missing_values[missing_values > 0])

if page == pages[2]:
    st.title("Visualisation des DonnÃ©es ğŸ“Š")
    st.subheader("Exploration des distributions des variables")
    selected_variable = st.selectbox("SÃ©lectionnez une variable :", df.columns)

    # VÃ©rification du type de variable pour choisir le bon type de graphique
    if df[selected_variable].dtype in ["int64", "float64"]:  
        st.subheader(f"Distribution de '{selected_variable}' (NumÃ©rique)")

        # CrÃ©ation de l'histogramme
        fig, ax = plt.subplots(figsize=(8, 5))
        df[selected_variable].hist(bins=20, ax=ax, color="royalblue", edgecolor="black")
        ax.set_xlabel(selected_variable)
        ax.set_ylabel("FrÃ©quence")
        ax.set_title(f"Histogramme de '{selected_variable}'")
        st.pyplot(fig)

    else: 
        st.subheader(f"Distribution de '{selected_variable}' (CatÃ©gorielle)")

        # CrÃ©ation du diagramme en barres
        fig, ax = plt.subplots(figsize=(8, 5))
        df[selected_variable].value_counts().plot(kind="bar", ax=ax, color="royalblue", edgecolor="black")
        ax.set_xlabel(selected_variable)
        ax.set_ylabel("Nombre d'occurrences")
        ax.set_title(f"RÃ©partition des catÃ©gories de '{selected_variable}'")
        st.pyplot(fig)

    # SÃ©lection des variables catÃ©gorielles et numÃ©riques
    categorical_vars = df.select_dtypes(include=["object"]).columns.tolist()
    numerical_vars = df.select_dtypes(include=["int64", "float64"]).columns.tolist()

    # Suppression de 'deposit' si elle est prÃ©sente
    if "deposit" in categorical_vars:
        categorical_vars.remove("deposit")
    if "deposit" in numerical_vars:
        numerical_vars.remove("deposit")

    def categorize_data(df):
        df = df.copy()
        df['age'] = pd.cut(df['age'], bins=[0, 25, 35, 45, 55, 65, float('inf')], 
                        labels=['<25', '25-35', '35-45', '45-55', '55-65', '>65'])
        df['campaign'] = pd.cut(df['campaign'], bins=[0, 1, 2, 6, float('inf')], 
                             labels=['1 fois', '2 fois', '3-6 fois', '>6 fois'])
        df['previous'] = pd.cut(df['previous'], bins=[-1, 0, 1, 5, float('inf')], 
                             labels=['jamais contactÃ© (0)', '1 seul contact', '2 Ã  5 contacts', 'plus de 6 contacts'])
        df['pdays'] = pd.cut(df['pdays'], bins=[-2, -1, 180, 365, float('inf')], 
                          labels=['Jamais contactÃ© (-1)', '0-6 mois', '6 mois-1 an', '> 1 an'])
        balance_bins = pd.qcut(df['balance'], q=4, duplicates='drop')
        balance_labels = [f"{int(interval.left)} - {int(interval.right)}" for interval in balance_bins.cat.categories]
        df['balance'] = pd.Categorical(balance_bins, categories=balance_bins.cat.categories, ordered=True)
        df['balance'] = df['balance'].cat.rename_categories(balance_labels)
        duration_bins = pd.qcut(df['duration'], q=4, duplicates='drop')
        duration_labels = [f"{int(interval.left)} - {int(interval.right)}" for interval in duration_bins.cat.categories]
        df['duration'] = pd.Categorical(duration_bins, categories=duration_bins.cat.categories, ordered=True)
        df['duration'] = df['duration'].cat.rename_categories(duration_labels)
        df['day'] = pd.to_datetime(df['day'], format='%d', errors='coerce').dt.day_name()
        return df
    new_1 = categorize_data(df)  # Appliquer la transformation
    categorical_vars = ['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 
                    'month', 'day', 'poutcome', 'age', 'campaign', 'previous', 'pdays', 'balance', 'duration']
    st.subheader("Analyse de la souscription ('deposit') en fonction des autres variables")
    selected_var = st.selectbox("Choisissez une variable Ã  comparer avec 'deposit':", categorical_vars)
    fig = go.Figure()
    grouped_data = new_1.groupby([selected_var, "deposit"]).size().reset_index(name="count")
    total_counts = grouped_data.groupby(selected_var)["count"].transform("sum")
    grouped_data["percentage"] = (grouped_data["count"] / total_counts) * 100
    colors = {"yes": "#003f5c", "no": "#d45087"}
    for deposit_value in ["yes", "no"]:
        filtered_data = grouped_data[grouped_data["deposit"] == deposit_value]
        fig.add_trace(go.Bar(
        x=filtered_data[selected_var], 
        y=filtered_data["percentage"], 
        name=f"{deposit_value}",
        marker_color=colors[deposit_value],
        text=filtered_data["percentage"].round(1).astype(str) + '%',
        textposition="inside"))
    fig.update_layout(
    title=f"Pourcentage de souscription ('deposit') en fonction de '{selected_var}'",
    barmode="stack",
    yaxis_title="Pourcentage (%)")
    st.plotly_chart(fig)

if page == pages[3]:
    st.title("PrÃ©processing ğŸ› ï¸")

      # PrÃ©sentation des principales Ã©tapes de prÃ©paration
    st.write("### Principales Ã©tapes de prÃ©paration des donnÃ©es")
    st.write("- Les valeurs 'unknown' et 'other' ont Ã©tÃ© remplacÃ©es par NaN pour signaler la prÃ©sence de valeurs manquantes.")
    st.write("- Les colonnes 'contact' et 'default' ont Ã©tÃ© supprimÃ©es car elles Ã©taient dominÃ©es par une seule modalitÃ©.")
    st.write("- L'analyse des corrÃ©lations a rÃ©vÃ©lÃ© une forte corrÃ©lation entre 'pdays' et 'previous', nous avons donc conservÃ© 'pdays'.")
    st.write("- Les variables binaires ont Ã©tÃ© encodÃ©es en valeurs numÃ©riques.")
    st.write("- Une nouvelle variable a Ã©tÃ© crÃ©Ã©e en combinant 'housing' et 'loan'.")
    st.write("- Une colonne binaire a Ã©tÃ© ajoutÃ©e pour indiquer si le client a Ã©tÃ© contactÃ© ou non.")   
    
    if st.button("Afficher la matrice de corrÃ©lation ğŸ”¢"):
        df_numeric = df.select_dtypes(include=["number"])
        corr_matrix = df_numeric.corr()
        fig, ax = plt.subplots(figsize=(8, 6))
        sns.heatmap(corr_matrix, annot=True, fmt=".2f", cmap="coolwarm", ax=ax)
        st.pyplot(fig)

    # Affichage du dataset avant nettoyage
    st.write("### Avant nettoyage")
    st.dataframe(df.head())
    
    # Affichage du dataset aprÃ¨s nettoyage
    st.write("### AprÃ¨s nettoyage")
    df_clean=pd.read_csv("https://raw.githubusercontent.com/Manal-art-coder/DataScientest_Project/main/df_clean.csv")
    st.dataframe(df_clean.head())
    
import os
import joblib
import pandas as pd
import matplotlib.pyplot as plt

if page == pages[4]:
    st.title("ModÃ¨les de Machine Learning ğŸ“¥")

    st.write("""SÃ©lectionnez un modÃ¨le de Machine Learning entraÃ®nÃ© et consultez ses performances.  
    Vous pouvez comparer plusieurs modÃ¨les et voir leurs scores de validation croisÃ©e.""")

    MODEL_DIR_URL = "https://raw.githubusercontent.com/Manal-art-coder/DataScientest_Project/main/Models/"
    model_files = ["AdaBoostClassifier.pkl", "BaggingClassifier.pkl", "DecisionTreeClassifier.pkl",
                   "GradientBoostingClassifier.pkl", "LogisticRegression.pkl", "RandomForestClassifier.pkl"]

    if not model_files:
        st.error("âŒ Aucun modÃ¨le trouvÃ©. Assurez-vous que les fichiers sont bien sur GitHub.")
    else:
        model_names = [f.replace(".pkl", "") for f in model_files]
        selected_model_name = st.selectbox("Choisissez un modÃ¨le :", model_names)
        selected_model_file = MODEL_DIR_URL + selected_model_name + ".pkl"  # âœ… Construire l'URL complÃ¨te

        try:
            response = requests.get(selected_model_file)
            if response.status_code == 200:
                selected_model = joblib.load(BytesIO(response.content))
                st.success(f"âœ… ModÃ¨le {selected_model_name} chargÃ© avec succÃ¨s !")
            else:
                st.error(f"âŒ Erreur {response.status_code} lors du chargement de {selected_model_file}")
                selected_model = None
        except Exception as e:
            st.error(f"âŒ Erreur lors du chargement du modÃ¨le {selected_model_name} : {e}")
            selected_model = None

        st.write(f"### Scores du modÃ¨le {selected_model_name}")

    SCORES_FILE_URL = "https://raw.githubusercontent.com/Manal-art-coder/DataScientest_Project/main/cross_val_results.csv"
    try:
        response = requests.get(SCORES_FILE_URL)
        if response.status_code == 200:
            cross_val_df = pd.read_csv(BytesIO(response.content))  # âœ… Lire correctement le CSV
            scores = cross_val_df[cross_val_df['Model'] == selected_model_name]
            st.dataframe(scores)

            st.write("### ğŸ“Š Comparaison des modÃ¨les")
            fig, ax = plt.subplots(figsize=(8, 5))  # Ajuster la taille du graphique
            cross_val_df.plot(x="Model", y=["Mean Recall", "Mean Precision", "Mean F1"], 
                              kind="bar", ax=ax, color=["#1f77b4", "#ff7f0e", "#2ca02c"])
            ax.set_xlabel("ModÃ¨les")
            ax.set_ylabel("Score")
            ax.set_title("Comparaison des scores des modÃ¨les")
            ax.legend(title="MÃ©triques", loc="upper right", fontsize=8)
            ax.tick_params(axis="x", rotation=30)
            st.pyplot(fig)
        else:
            st.error(f"âŒ Erreur {response.status_code} : impossible de charger les rÃ©sultats.")

    except Exception as e:
        st.error(f"âŒ Erreur lors du chargement du fichier des scores : {e}")

        
if page==pages[5]:
    st.title("Meilleur modÃ¨le ğŸ“¥")
    BASE_URL = "https://raw.githubusercontent.com/Manal-art-coder/DataScientest_Project/main/"
    files = {
    "model": "final_model.pkl",
    "performance": "model_performance.csv",
    "conf_matrix_before": "conf_matrix_before.npy",
    "conf_matrix_after": "conf_matrix_after.npy",
    "conf_matrix_optimal": "conf_matrix_optimal.npy",
    "feat_importance_before": "feature_importance_before.csv",
    "feat_importance_after": "feature_importance_after.csv",
    "y_probs": "y_probs.npy",
    "y_test": "y_test.npy"}
    def load_file(url, is_numpy=False, is_pkl=False):
        response = requests.get(url)
        if response.status_code == 200:
            if is_numpy:
                return np.load(response.raw, allow_pickle=True)
            elif is_pkl:
                return joblib.load(response.raw)
            else:
                return pd.read_csv(url)
        else:
            st.error(f"âŒ Erreur {response.status_code} : impossible de charger {url}")
        return None

    # ğŸ” Chargement des fichiers
    model = load_file(BASE_URL + files["model"], is_pkl=True)
    performance_df = load_file(BASE_URL + files["performance"])
    conf_matrix_before = load_file(BASE_URL + files["conf_matrix_before"], is_numpy=True)
    conf_matrix_after = load_file(BASE_URL + files["conf_matrix_after"], is_numpy=True)
    conf_matrix_optimal = load_file(BASE_URL + files["conf_matrix_optimal"], is_numpy=True)
    feat_importance_before = load_file(BASE_URL + files["feat_importance_before"])
    feat_importance_after = load_file(BASE_URL + files["feat_importance_after"])
    y_probs = load_file(BASE_URL + files["y_probs"], is_numpy=True)
    y_test = load_file(BASE_URL + files["y_test"], is_numpy=True)

    st.title("Optimisation du ModÃ¨le de Machine Learning")
    st.sidebar.header("Navigation")
    step = st.sidebar.radio("SÃ©lectionnez une Ã©tape :", ["1ï¸âƒ£ Performances", "2ï¸âƒ£ Feature Importance", "3ï¸âƒ£ Matrice de Confusion", "4ï¸âƒ£ Courbe ROC"])

    if step == "1ï¸âƒ£ Performances":
        st.subheader("Comparaison des Performances du ModÃ¨le")
        if performance_df is not None:
            st.dataframe(performance_df)
            fig, ax = plt.subplots(figsize=(10, 5))
            performance_df.set_index("Step").plot(kind="bar", ax=ax)
            plt.title("Ã‰volution des Scores")
            plt.ylabel("Score")
            plt.xticks(rotation=0)
            st.pyplot(fig)

    elif step == "2ï¸âƒ£ Feature Importance":
        st.subheader("Importance des Features")
        choix = st.radio("Choisissez :", ["Avant Optimisation", "AprÃ¨s Optimisation"])
        feat_data = feat_importance_before if choix == "Avant Optimisation" else feat_importance_after
        if feat_data is not None:
            fig, ax = plt.subplots(figsize=(10, 5))
            sns.barplot(data=feat_data.head(10), x="Importance", y="Variable", ax=ax, palette="Blues_r")
            plt.title(f"Top Features ({choix})")
            st.pyplot(fig)

    elif step == "3ï¸âƒ£ Matrice de Confusion":
        st.subheader("Comparaison des Matrices de Confusion")
        choix = st.radio("Choisissez :", ["Avant Optimisation", "AprÃ¨s HyperparamÃ¨tres", "AprÃ¨s Seuil"])
        matrix = conf_matrix_before if choix == "Avant Optimisation" else conf_matrix_after if choix == "AprÃ¨s HyperparamÃ¨tres" else conf_matrix_optimal
        if matrix is not None:
            fig, ax = plt.subplots()
            ConfusionMatrixDisplay(matrix).plot(ax=ax, cmap='Blues')
            plt.title(f"Matrice de Confusion ({choix})")
            st.pyplot(fig)

    elif step == "4ï¸âƒ£ Courbe ROC":
        st.subheader("Courbe ROC et Seuil Optimal")
        if y_probs is not None and y_test is not None:
            fpr, tpr, thresholds = roc_curve(y_test, y_probs)
            roc_auc = auc(fpr, tpr)

            best_f1 = 0
            best_threshold = 0
            for threshold in thresholds:
                y_pred_temp = (y_probs > threshold).astype(int)
                f1 = f1_score(y_test, y_pred_temp)
                if f1 > best_f1:
                    best_f1 = f1
                    best_threshold = threshold

            st.write(f"**Seuil optimal basÃ© sur le F1-score** : {best_threshold:.2f}")
            st.write(f"**Meilleur F1-score obtenu** : {best_f1:.4f}")

            fig, ax = plt.subplots(figsize=(8, 6))
            ax.plot(fpr, tpr, color='blue', label=f'ROC curve (AUC = {roc_auc:.2f})')
            ax.plot([0, 1], [0, 1], color='gray', linestyle='--')
            ax.set_xlabel('Taux de Faux Positifs')
            ax.set_ylabel('Taux de Vrais Positifs')
            ax.set_title('Courbe ROC')
            ax.legend()
            st.pyplot(fig)


if page == pages[6]:
    st.title("ğŸ” PrÃ©diction de souscription d'un client Ã  un compte Ã  terme")

    st.subheader("ğŸ“ Entrez les caractÃ©ristiques du client :")
    age = st.number_input("Ã‚ge", min_value=18, max_value=100, value=30)
    education = st.selectbox("Niveau d'Ã©ducation", options=["primary", "secondary", "tertiary"])
    balance = st.number_input("Solde du compte bancaire", value=0.0)
    housing = st.radio("PossÃ¨de un prÃªt immobilier ?", options=["Oui", "Non"])
    day = st.number_input("Jour du contact", min_value=1, max_value=31, value=15)
    month = st.selectbox("Mois du contact", options=['jan', 'feb', 'mar', 'apr', 'may', 'jun', 'jul', 'aug', 'sep', 'oct', 'nov', 'dec'])
    duration = st.number_input("DurÃ©e de l'appel (en secondes)", min_value=0, value=100)
    poutcome = st.radio("RÃ©sultat de la campagne prÃ©cÃ©dente ?", options=["Success", "Failure", "missing"])
    pdays_contacted = st.radio("DÃ©jÃ  contactÃ© ?", options=["Oui", "Non"])
    campaign = st.selectbox("Nombre de contacts durant cette campagne", options=["1 fois", "2 fois", "3-6 fois", "> 6 fois"])

    # Mapping des variables catÃ©goriques
    education_mapping = {"primary": 0, "secondary": 1, "tertiary": 2}
    month_mapping = {'jan': 1, 'feb': 2, 'mar': 3, 'apr': 4, 'may': 5, 'jun': 6,
                     'jul': 7, 'aug': 8, 'sep': 9, 'oct': 10, 'nov': 11, 'dec': 12}
    
    education = education_mapping[education]
    housing = 1 if housing == "Oui" else 0
    pdays_contacted = 1 if pdays_contacted == "Oui" else 0
    month = month_mapping[month]

    # CrÃ©ation du DataFrame utilisateur
    user_data = pd.DataFrame([[age, education, balance, housing, day, month, duration, pdays_contacted, campaign, poutcome]],
                             columns=['age', 'education', 'balance', 'housing', 'day', 'month', 'duration', 'pdays_contacted', 'campaign', 'poutcome'])

    # One-Hot Encoding
    one_hot_cols = ['campaign', 'poutcome']
    encoder = OneHotEncoder(drop='first', sparse_output=False, handle_unknown='ignore')

    encoded_data = encoder.fit_transform(user_data[one_hot_cols])
    encoded_df = pd.DataFrame(encoded_data, columns=encoder.get_feature_names_out(one_hot_cols))
    user_data = pd.concat([user_data.drop(columns=one_hot_cols), encoded_df], axis=1)

    # Chargement du modÃ¨le et du scaler depuis GitHub
    try:
        main_dir = "https://raw.githubusercontent.com/Manal-art-coder/DataScientest_Project/main/"
        model_url = main_dir + "final_model.pkl"
        scaler_url = main_dir + "scaler.pkl"

        # TÃ©lÃ©charger le modÃ¨le
        response = requests.get(model_url)
        response.raise_for_status()
        model = joblib.load(BytesIO(response.content))

        # Ajouter les colonnes manquantes
        expected_columns = model.feature_names_in_
        for col in expected_columns:
            if col not in user_data.columns:
                user_data[col] = 0
        user_data = user_data[expected_columns]

        # TÃ©lÃ©charger et appliquer le scaler
        response = requests.get(scaler_url)
        response.raise_for_status()
        scaler = joblib.load(BytesIO(response.content))

        numerical_columns = ['age', 'balance', 'day', 'duration']
        existing_numerical_columns = [col for col in numerical_columns if col in user_data.columns]
        user_data[existing_numerical_columns] = scaler.transform(user_data[existing_numerical_columns])

        # PrÃ©diction
        if st.button("ğŸ” PrÃ©dire"):
            prediction = model.predict(user_data)[0]
            st.write("ğŸ”® PrÃ©diction brute :", prediction)
            result = "âœ… Le client VA souscrire" if prediction == 1 else "âŒ Le client NE souscrira PAS"
            st.success(result)

    except Exception as e:
        st.error(f"âŒ Erreur : {e}")

    # ğŸ“¥ Upload de fichier CSV
    uploaded_file = st.file_uploader("ğŸ“¥ TÃ©lÃ©chargez votre fichier CSV", type=["csv"])

    if uploaded_file is not None:
        user_data = pd.read_csv(uploaded_file)
        st.write("âœ… DonnÃ©es chargÃ©es avec succÃ¨s !")

        # Traitement des valeurs inconnues
        user_data.replace(["unknown", "Unknown", "UNKNOWN", "other", "Other", "OTHER"], np.nan, inplace=True)
        if 'pdays' in user_data.columns:
            user_data['pdays_contacted'] = (user_data['pdays'] != -1).astype(int)

        # Suppression de colonnes inutiles
        columns_to_drop = ['default', 'contact', 'previous', 'pdays']
        user_data.drop(columns=[col for col in columns_to_drop if col in user_data.columns], inplace=True)

        # Encodage et transformation
        categorical_imputer = SimpleImputer(strategy='most_frequent')
        one_hot_cols = ['job', 'marital', 'poutcome', 'campaign']
        encoder = OneHotEncoder(drop='first', sparse_output=False, handle_unknown='ignore')

        if all(col in user_data.columns for col in one_hot_cols):
            encoded_data = encoder.fit_transform(user_data[one_hot_cols])
            encoded_df = pd.DataFrame(encoded_data, columns=encoder.get_feature_names_out(one_hot_cols))
            user_data = pd.concat([user_data.drop(columns=one_hot_cols), encoded_df], axis=1)

        numerical_columns = ['age', 'balance', 'day', 'duration']
        scaler = RobustScaler()
        if all(col in user_data.columns for col in numerical_columns):
            user_data[numerical_columns] = scaler.fit_transform(user_data[numerical_columns])

        st.write("ğŸ“Š DonnÃ©es aprÃ¨s prÃ©traitement :")
        st.dataframe(user_data.head())

        # TÃ©lÃ©chargement des donnÃ©es transformÃ©es
        csv_buffer = io.BytesIO()
        user_data.to_csv(csv_buffer, index=False)
        csv_buffer.seek(0)
        st.download_button(label="ğŸ“¥ TÃ©lÃ©charger les donnÃ©es prÃ©traitÃ©es", data=csv_buffer, file_name="transformed_data.csv", mime="text/csv")

        # PrÃ©diction sur les donnÃ©es chargÃ©es
        try:
            prediction = model.predict(user_data)
            user_data["PrÃ©diction"] = ["Souscrit âœ…" if p == 1 else "Ne souscrit pas âŒ" for p in prediction]
            st.dataframe(user_data)

        except Exception as e:
            st.error(f"âŒ Erreur lors de la prÃ©diction : {e}")

if page == pages[7]:
    st.write("## ğŸ“Š Conclusion & Recommandations")

    st.write("### ğŸ” RÃ©sumÃ© des rÃ©sultats")
    st.write("""
    Notre modÃ¨le final a confirmÃ© plusieurs tendances observÃ©es lors de la phase d'exploration des donnÃ©es :
    - **DurÃ©e du dernier contact ğŸ“** : TrÃ¨s corrÃ©lÃ©e avec la souscription, mais problÃ©matique pour une prÃ©diction en amont.
    - **PÃ©riode des campagnes ğŸ“…** : Mai est inefficace, alors que septembre et octobre sont plus favorables.
    - **Ciblage par Ã¢ge ğŸ‘¥** : Les jeunes (-25 ans) et les seniors (+65 ans) souscrivent davantage.
    - **Jours de contact optimaux ğŸ“†** : mardi, mercredi et jeudi offrent les meilleurs taux de conversion.
    - **Solde du compte ğŸ’°** : Plus il est Ã©levÃ©, plus la souscription est probable.
    - **Impact des prÃªts ğŸ¦** : Les clients avec un prÃªt immobilier sont moins enclins Ã  souscrire Ã  un DAT.
    """)

    st.write("### ğŸ“Œ Recommandations stratÃ©giques")
    st.markdown("""
    ğŸ”¹ **Optimisation des campagnes**  
    - Cibler les campagnes en septembre/octobre plutÃ´t qu'en mai.  
    - Planifier les appels principalement en milieu de semaine.  
      
    ğŸ”¹ **AmÃ©lioration du ciblage client**  
    - Segmenter les clients en fonction de leur solde bancaire.  
    - PrivilÃ©gier les profils ayant rÃ©pondu positivement Ã  des campagnes prÃ©cÃ©dentes.  
      
    ğŸ”¹ **StratÃ©gie dâ€™engagement client**  
    - Former les Ã©quipes pour prolonger la durÃ©e des appels et amÃ©liorer le taux de conversion.  
    - Personnaliser les offres en fonction des besoins spÃ©cifiques des tranches dâ€™Ã¢ge.  
    """)

if page ==pages[8]:
    st.write("## ğŸš€ DifficultÃ©s rencontrÃ©es & Perspectives")
    st.write("""
    ğŸ”¹ **Utilisation de la variable duration**  
    - Variable informative mais inutilisable en amont.  
    - Son retrait a diminuÃ© les performances du modÃ¨le.  
      
    ğŸ”¹ **ModÃ©lisation et choix des algorithmes**  
    - Test de plusieurs modÃ¨les avant dâ€™identifier le meilleur.  
    - DifficultÃ© Ã  choisir entre prÃ©diction avant ou aprÃ¨s le premier contact.  
      
    ğŸ”¹ **ProblÃ¨mes de donnÃ©es**  
    - Valeurs inconnues dans certaines variables (`poutcome`, `education`).  
    - DÃ©sÃ©quilibre des campagnes passÃ©es compliquant l'analyse des rÃ©sultats.  
    """)

    st.write("### ğŸ¯ Bilan et rÃ©sultats obtenus")
    st.markdown("""
    - **ModÃ¨le final** : PrÃ©cision **85%** et F1-score **0.83**.  
    - **Benchmark** : RÃ©sultats compÃ©titifs par rapport aux standards du secteur bancaire.  
    - **Impact business** : AmÃ©lioration de lâ€™efficacitÃ© des campagnes marketing.  
    """)

    st.write("### ğŸ” Pistes dâ€™amÃ©lioration")
    st.markdown("""
    âœ… **AmÃ©liorer les variables** en crÃ©ant de nouvelles interactions (Ã¢ge & statut pro, solde & prÃªt).   
    âœ… **Tester lâ€™utilisation de duration** en la prÃ©disant dans un modÃ¨le sÃ©parÃ©.  
    âœ… **Test A/B** pour valider les recommandations sur un Ã©chantillon rÃ©el.  
    """)
    st.success("Ce projet nous a permis d'explorer des problÃ©matiques rÃ©elles de Machine Learning appliquÃ©es au marketing bancaire et de mieux comprendre l'importance des variables temporelles dans la prÃ©diction.")



      

      
        
      


    



        


