import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.graph_objects as go
import plotly.express as px
from scipy.stats import chi2_contingency
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.preprocessing import OneHotEncoder, RobustScaler
from sklearn.impute import SimpleImputer
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier, BaggingClassifier, AdaBoostClassifier, GradientBoostingClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import recall_score, precision_score, accuracy_score, f1_score, classification_report, precision_recall_curve, PrecisionRecallDisplay,  confusion_matrix, ConfusionMatrixDisplay, roc_curve, auc
import joblib
from sklearn.utils.validation import check_is_fitted
import os

df=pd.read_csv(r"https://raw.githubusercontent.com/Manal-art-coder/DataScientest_Project/main/bank.csv")
df.head()
st.title("Pr√©diction du succ√®s d'une campagne Marketing")
st.sidebar.title("Sommaire")
pages=["Contexte & enjeux", "Pr√©sentation des donn√©es", "Visualisation des donn√©es", "Pr√©processing", "Mod√®les ML", "Meilleur mod√®le", "Faites votre propre pr√©diction !","Conclusion & Recommandations", "Difficult√©s & perspectives"]
page=st.sidebar.radio("Aller vers", pages)

if page == pages[0]: 
    # üî∑ Section Contexte & Enjeux
    st.write("### üìå Contexte & Enjeux")
    
    # Ajout d'une image d'illustration
    st.image(r"https://raw.githubusercontent.com/Manal-art-coder/DataScientest_Project/main/Screenshot 2025-02-19 111852.jpg", use_column_width=True)
    
    st.write("""
    Ce projet s‚Äôinscrit dans le cadre de notre formation de **Data Analyst** avec l‚Äôorganisme **DataScientest**.  

    ### üéØ Objectif du projet  
    L‚Äôobjectif est d‚Äôanalyser et pr√©dire le succ√®s d‚Äôune **campagne marketing bancaire** en identifiant les facteurs influen√ßant la souscription des clients √† une offre de d√©p√¥t √† terme.  

    ### üìä Donn√©es utilis√©es  
    - Le dataset provient de la plateforme **Kaggle**, accessible ici : [Bank Marketing Dataset](https://www.kaggle.com/datasets/janiobachmann/bank-marketing-dataset).  
    - Il contient des informations d√©taill√©es sur les clients, les interactions pass√©es et les r√©sultats des campagnes marketing.  

    ### üîç D√©marche adopt√©e  
    Ce **Tableau de bord interactif Streamlit** retrace toutes les √©tapes du projet :  
    1. Exploration et pr√©traitement des donn√©es  
    2. Visualisation des variables explicatives  
    3. Mise en place et comparaison de plusieurs **mod√®les de Machine Learning**  
    4. S√©lection du mod√®le le plus performant  
    5. **Pr√©diction en temps r√©el** sur de nouvelles donn√©es  

    üì¢ Ce projet permet ainsi de mieux comprendre les dynamiques des campagnes marketing et d'optimiser les strat√©gies commerciales ! üöÄ
    """)

    # üî∑ Section √âquipe du Projet
    st.write("### üë• √âquipe du Projet")

    # üìå Liste des membres de l'√©quipe
    team_members = [
        {"nom": "Jewa", "prenom": "Manal", "linkedin": "https://www.linkedin.com/in/manaljewa/"},
        {"nom": "Selle", "prenom": "Manon", "linkedin": "https://www.linkedin.com/in/manon-selle/"},
        {"nom": "Demeulemeester", "prenom": "Elyse", "linkedin": "https://www.linkedin.com/in/elyse-demeulemeester-aa41832b7/"},
        {"nom": "Amiel", "prenom": "Audrey", "linkedin": "https://www.linkedin.com/in/audrey-amiel/"},
        {"nom": "Legrand", "prenom": "David", "linkedin": "https://www.linkedin.com/in/lucas-morel"}
    ]

    # üìå Affichage des membres sur deux lignes
    col1, col2, col3 = st.columns(3)  # Premi√®re ligne (3 colonnes)
    col4, col5 = st.columns(2)  # Deuxi√®me ligne (2 colonnes)

    columns = [col1, col2, col3, col4, col5]

    for col, member in zip(columns, team_members):
        with col:
            st.write(f"**{member['prenom']} {member['nom']}**")
            st.markdown(f"[LinkedIn]({member['linkedin']})")  # Lien vers le profil LinkedIn

if page == pages[1]:
    # Titre principal
    st.title("Pr√©sentation des donn√©es üìä")

    # Aper√ßu du dataset
    st.subheader("Aper√ßu des premi√®res lignes")
    st.write("Voici un aper√ßu des 10 premi√®res lignes du jeu de donn√©es :")
    st.dataframe(df.head(10))

    # Taille du dataset
    st.subheader("Taille du Dataset")
    st.write(f"**Nombre de lignes** : {df.shape[0]}")
    st.write(f"**Nombre de colonnes** : {df.shape[1]}")
    st.subheader("Types des Variables dans le Dataset")
    categorical_vars = df.select_dtypes(include=['object', 'category']).columns.tolist()
    numerical_vars = df.select_dtypes(include=['int64', 'float64']).columns.tolist()
    if st.button("Afficher les types des variables"):
        st.dataframe(df.dtypes.reset_index().rename(columns={"index": "Variable", 0: "Type"}))
    if st.button("Afficher les variables cat√©gorielles"):
        st.write("### Variables Cat√©gorielles")
        st.write(categorical_vars)
    if st.button("Afficher les variables num√©riques"):
        st.write("### Variables Num√©riques")
        st.write(numerical_vars)    

    # Statistiques descriptives
    st.subheader("Statistiques Descriptives")
    st.write("R√©sum√© statistique des variables num√©riques du dataset :")
    st.dataframe(df.describe())

    # V√©rification des valeurs manquantes
    st.subheader("Valeurs Manquantes")
    if st.checkbox("Afficher les valeurs manquantes üîç"):
        missing_values = df.isna().sum()
        if missing_values.sum() == 0:
            st.success("Aucune valeur manquante dans le dataset ! ‚úÖ")
        else:
            st.dataframe(missing_values[missing_values > 0])

if page == pages[2]:
    st.title("Visualisation des Donn√©es üìä")
    st.subheader("Exploration des distributions des variables")
    selected_variable = st.selectbox("S√©lectionnez une variable :", df.columns)

    # V√©rification du type de variable pour choisir le bon type de graphique
    if df[selected_variable].dtype in ["int64", "float64"]:  
        st.subheader(f"Distribution de '{selected_variable}' (Num√©rique)")

        # Cr√©ation de l'histogramme
        fig, ax = plt.subplots(figsize=(8, 5))
        df[selected_variable].hist(bins=20, ax=ax, color="royalblue", edgecolor="black")
        ax.set_xlabel(selected_variable)
        ax.set_ylabel("Fr√©quence")
        ax.set_title(f"Histogramme de '{selected_variable}'")
        st.pyplot(fig)

    else: 
        st.subheader(f"Distribution de '{selected_variable}' (Cat√©gorielle)")

        # Cr√©ation du diagramme en barres
        fig, ax = plt.subplots(figsize=(8, 5))
        df[selected_variable].value_counts().plot(kind="bar", ax=ax, color="royalblue", edgecolor="black")
        ax.set_xlabel(selected_variable)
        ax.set_ylabel("Nombre d'occurrences")
        ax.set_title(f"R√©partition des cat√©gories de '{selected_variable}'")
        st.pyplot(fig)

    # S√©lection des variables cat√©gorielles et num√©riques
    categorical_vars = df.select_dtypes(include=["object"]).columns.tolist()
    numerical_vars = df.select_dtypes(include=["int64", "float64"]).columns.tolist()

    # Suppression de 'deposit' si elle est pr√©sente
    if "deposit" in categorical_vars:
        categorical_vars.remove("deposit")
    if "deposit" in numerical_vars:
        numerical_vars.remove("deposit")

    def categorize_data(df):
        df = df.copy()
        df['age'] = pd.cut(df['age'], bins=[0, 25, 35, 45, 55, 65, float('inf')], 
                        labels=['<25', '25-35', '35-45', '45-55', '55-65', '>65'])
        df['campaign'] = pd.cut(df['campaign'], bins=[0, 1, 2, 6, float('inf')], 
                             labels=['1 fois', '2 fois', '3-6 fois', '>6 fois'])
        df['previous'] = pd.cut(df['previous'], bins=[-1, 0, 1, 5, float('inf')], 
                             labels=['jamais contact√© (0)', '1 seul contact', '2 √† 5 contacts', 'plus de 6 contacts'])
        df['pdays'] = pd.cut(df['pdays'], bins=[-2, -1, 180, 365, float('inf')], 
                          labels=['Jamais contact√© (-1)', '0-6 mois', '6 mois-1 an', '> 1 an'])
        balance_bins = pd.qcut(df['balance'], q=4, duplicates='drop')
        balance_labels = [f"{int(interval.left)} - {int(interval.right)}" for interval in balance_bins.cat.categories]
        df['balance'] = pd.Categorical(balance_bins, categories=balance_bins.cat.categories, ordered=True)
        df['balance'] = df['balance'].cat.rename_categories(balance_labels)
        duration_bins = pd.qcut(df['duration'], q=4, duplicates='drop')
        duration_labels = [f"{int(interval.left)} - {int(interval.right)}" for interval in duration_bins.cat.categories]
        df['duration'] = pd.Categorical(duration_bins, categories=duration_bins.cat.categories, ordered=True)
        df['duration'] = df['duration'].cat.rename_categories(duration_labels)
        df['day'] = pd.to_datetime(df['day'], format='%d', errors='coerce').dt.day_name()
        return df
    new_1 = categorize_data(df)  # Appliquer la transformation
    categorical_vars = ['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 
                    'month', 'day', 'poutcome', 'age', 'campaign', 'previous', 'pdays', 'balance', 'duration']
    st.subheader("Analyse de la souscription ('deposit') en fonction des autres variables")
    selected_var = st.selectbox("Choisissez une variable √† comparer avec 'deposit':", categorical_vars)
    fig = go.Figure()
    grouped_data = new_1.groupby([selected_var, "deposit"]).size().reset_index(name="count")
    total_counts = grouped_data.groupby(selected_var)["count"].transform("sum")
    grouped_data["percentage"] = (grouped_data["count"] / total_counts) * 100
    colors = {"yes": "#003f5c", "no": "#d45087"}
    for deposit_value in ["yes", "no"]:
        filtered_data = grouped_data[grouped_data["deposit"] == deposit_value]
        fig.add_trace(go.Bar(
        x=filtered_data[selected_var], 
        y=filtered_data["percentage"], 
        name=f"{deposit_value}",
        marker_color=colors[deposit_value],
        text=filtered_data["percentage"].round(1).astype(str) + '%',
        textposition="inside"))
    fig.update_layout(
    title=f"Pourcentage de souscription ('deposit') en fonction de '{selected_var}'",
    barmode="stack",
    yaxis_title="Pourcentage (%)")
    st.plotly_chart(fig)

if page == pages[3]:
    st.title("Pr√©processing üõ†Ô∏è")

      # Pr√©sentation des principales √©tapes de pr√©paration
    st.write("### Principales √©tapes de pr√©paration des donn√©es")
    st.write("- Les valeurs 'unknown' et 'other' ont √©t√© remplac√©es par NaN pour signaler la pr√©sence de valeurs manquantes.")
    st.write("- Les colonnes 'contact' et 'default' ont √©t√© supprim√©es car elles √©taient domin√©es par une seule modalit√©.")
    st.write("- L'analyse des corr√©lations a r√©v√©l√© une forte corr√©lation entre 'pdays' et 'previous', nous avons donc conserv√© 'pdays'.")
    st.write("- Les variables binaires ont √©t√© encod√©es en valeurs num√©riques.")
    st.write("- Une nouvelle variable a √©t√© cr√©√©e en combinant 'housing' et 'loan'.")
    st.write("- Une colonne binaire a √©t√© ajout√©e pour indiquer si le client a √©t√© contact√© ou non.")   
    
    if st.button("Afficher la matrice de corr√©lation üî¢"):
        df_numeric = df.select_dtypes(include=["number"])
        corr_matrix = df_numeric.corr()
        fig, ax = plt.subplots(figsize=(8, 6))
        sns.heatmap(corr_matrix, annot=True, fmt=".2f", cmap="coolwarm", ax=ax)
        st.pyplot(fig)

    # Affichage du dataset avant nettoyage
    st.write("### Avant nettoyage")
    st.dataframe(df.head())
    
    # Affichage du dataset apr√®s nettoyage
    st.write("### Apr√®s nettoyage")
    df_clean=pd.read_csv("https://raw.githubusercontent.com/Manal-art-coder/DataScientest_Project/main/df_clean.csv")
    st.dataframe(df_clean.head())
    
import os
import joblib
import pandas as pd
import matplotlib.pyplot as plt

if page == pages[4]:
    st.title("Mod√®les de Machine Learning üì•")

    st.write("""S√©lectionnez un mod√®le de Machine Learning entra√Æn√© et consultez ses performances.  
    Vous pouvez comparer plusieurs mod√®les et voir leurs scores de validation crois√©e.""")

    MODEL_DIR_URL = "https://raw.githubusercontent.com/Manal-art-coder/DataScientest_Project/main/Models/"
    model_files = ["AdaBoostClassifier.pkl", "BaggingClassifier.pkl", "DecisionTreeClassifier.pkl",
                   "GradientBoostingClassifier.pkl", "LogisticRegression.pkl", "RandomForestClassifier.pkl"]

    if not model_files:
        st.error("‚ùå Aucun mod√®le trouv√©. Assurez-vous que les fichiers sont bien sur GitHub.")
    else:
        model_names = [f.replace(".pkl", "") for f in model_files]
        selected_model_name = st.selectbox("Choisissez un mod√®le :", model_names)
        selected_model_file = MODEL_DIR_URL + selected_model_name + ".pkl"  # ‚úÖ Construire l'URL compl√®te

        try:
            response = requests.get(selected_model_file)
            if response.status_code == 200:
                selected_model = joblib.load(BytesIO(response.content))
                st.success(f"‚úÖ Mod√®le {selected_model_name} charg√© avec succ√®s !")
            else:
                st.error(f"‚ùå Erreur {response.status_code} lors du chargement de {selected_model_file}")
                selected_model = None
        except Exception as e:
            st.error(f"‚ùå Erreur lors du chargement du mod√®le {selected_model_name} : {e}")
            selected_model = None

        st.write(f"### Scores du mod√®le {selected_model_name}")

    SCORES_FILE_URL = "https://raw.githubusercontent.com/Manal-art-coder/DataScientest_Project/main/cross_val_results.csv"
    try:
        response = requests.get(SCORES_FILE_URL)
        if response.status_code == 200:
            cross_val_df = pd.read_csv(BytesIO(response.content))  # ‚úÖ Lire correctement le CSV
            scores = cross_val_df[cross_val_df['Model'] == selected_model_name]
            st.dataframe(scores)

            st.write("### üìä Comparaison des mod√®les")
            fig, ax = plt.subplots(figsize=(8, 5))  # Ajuster la taille du graphique
            cross_val_df.plot(x="Model", y=["Mean Recall", "Mean Precision", "Mean F1"], 
                              kind="bar", ax=ax, color=["#1f77b4", "#ff7f0e", "#2ca02c"])
            ax.set_xlabel("Mod√®les")
            ax.set_ylabel("Score")
            ax.set_title("Comparaison des scores des mod√®les")
            ax.legend(title="M√©triques", loc="upper right", fontsize=8)
            ax.tick_params(axis="x", rotation=30)
            st.pyplot(fig)
        else:
            st.error(f"‚ùå Erreur {response.status_code} : impossible de charger les r√©sultats.")

    except Exception as e:
        st.error(f"‚ùå Erreur lors du chargement du fichier des scores : {e}")

        
if page==pages[5]:
    st.title("Meilleur mod√®le üì•")
    BASE_URL = "https://raw.githubusercontent.com/Manal-art-coder/DataScientest_Project/main/"
    files = {
    "model": "final_model.pkl",
    "performance": "model_performance.csv",
    "conf_matrix_before": "conf_matrix_before.npy",
    "conf_matrix_after": "conf_matrix_after.npy",
    "conf_matrix_optimal": "conf_matrix_optimal.npy",
    "feat_importance_before": "feature_importance_before.csv",
    "feat_importance_after": "feature_importance_after.csv",
    "y_probs": "y_probs.npy",
    "y_test": "y_test.npy"}
    def load_file(url, is_numpy=False, is_pkl=False):
        response = requests.get(url)
        if response.status_code == 200:
            if is_numpy:
                return np.load(response.raw, allow_pickle=True)
            elif is_pkl:
                return joblib.load(response.raw)
            else:
                return pd.read_csv(url)
        else:
            st.error(f"‚ùå Erreur {response.status_code} : impossible de charger {url}")
        return None

    # üîç Chargement des fichiers
    model = load_file(BASE_URL + files["model"], is_pkl=True)
    performance_df = load_file(BASE_URL + files["performance"])
    conf_matrix_before = load_file(BASE_URL + files["conf_matrix_before"], is_numpy=True)
    conf_matrix_after = load_file(BASE_URL + files["conf_matrix_after"], is_numpy=True)
    conf_matrix_optimal = load_file(BASE_URL + files["conf_matrix_optimal"], is_numpy=True)
    feat_importance_before = load_file(BASE_URL + files["feat_importance_before"])
    feat_importance_after = load_file(BASE_URL + files["feat_importance_after"])
    y_probs = load_file(BASE_URL + files["y_probs"], is_numpy=True)
    y_test = load_file(BASE_URL + files["y_test"], is_numpy=True)

    st.title("Optimisation du Mod√®le de Machine Learning")
    st.sidebar.header("Navigation")
    step = st.sidebar.radio("S√©lectionnez une √©tape :", ["1Ô∏è‚É£ Performances", "2Ô∏è‚É£ Feature Importance", "3Ô∏è‚É£ Matrice de Confusion", "4Ô∏è‚É£ Courbe ROC"])

    if step == "1Ô∏è‚É£ Performances":
        st.subheader("Comparaison des Performances du Mod√®le")
        if performance_df is not None:
            st.dataframe(performance_df)
            fig, ax = plt.subplots(figsize=(10, 5))
            performance_df.set_index("Step").plot(kind="bar", ax=ax)
            plt.title("√âvolution des Scores")
            plt.ylabel("Score")
            plt.xticks(rotation=0)
            st.pyplot(fig)

    elif step == "2Ô∏è‚É£ Feature Importance":
        st.subheader("Importance des Features")
        choix = st.radio("Choisissez :", ["Avant Optimisation", "Apr√®s Optimisation"])
        feat_data = feat_importance_before if choix == "Avant Optimisation" else feat_importance_after
        if feat_data is not None:
            fig, ax = plt.subplots(figsize=(10, 5))
            sns.barplot(data=feat_data.head(10), x="Importance", y="Variable", ax=ax, palette="Blues_r")
            plt.title(f"Top Features ({choix})")
            st.pyplot(fig)

    elif step == "3Ô∏è‚É£ Matrice de Confusion":
        st.subheader("Comparaison des Matrices de Confusion")
        choix = st.radio("Choisissez :", ["Avant Optimisation", "Apr√®s Hyperparam√®tres", "Apr√®s Seuil"])
        matrix = conf_matrix_before if choix == "Avant Optimisation" else conf_matrix_after if choix == "Apr√®s Hyperparam√®tres" else conf_matrix_optimal
        if matrix is not None:
            fig, ax = plt.subplots()
            ConfusionMatrixDisplay(matrix).plot(ax=ax, cmap='Blues')
            plt.title(f"Matrice de Confusion ({choix})")
            st.pyplot(fig)

    elif step == "4Ô∏è‚É£ Courbe ROC":
        st.subheader("Courbe ROC et Seuil Optimal")
        if y_probs is not None and y_test is not None:
            fpr, tpr, thresholds = roc_curve(y_test, y_probs)
            roc_auc = auc(fpr, tpr)

            best_f1 = 0
            best_threshold = 0
            for threshold in thresholds:
                y_pred_temp = (y_probs > threshold).astype(int)
                f1 = f1_score(y_test, y_pred_temp)
                if f1 > best_f1:
                    best_f1 = f1
                    best_threshold = threshold

            st.write(f"**Seuil optimal bas√© sur le F1-score** : {best_threshold:.2f}")
            st.write(f"**Meilleur F1-score obtenu** : {best_f1:.4f}")

            fig, ax = plt.subplots(figsize=(8, 6))
            ax.plot(fpr, tpr, color='blue', label=f'ROC curve (AUC = {roc_auc:.2f})')
            ax.plot([0, 1], [0, 1], color='gray', linestyle='--')
            ax.set_xlabel('Taux de Faux Positifs')
            ax.set_ylabel('Taux de Vrais Positifs')
            ax.set_title('Courbe ROC')
            ax.legend()
            st.pyplot(fig)


if page == pages[6]:
    st.title("üîç Pr√©diction de souscription d'un client √† un compte √† terme")

    st.subheader("üìù Entrez les caract√©ristiques du client :")
    age = st.number_input("√Çge", min_value=18, max_value=100, value=30)
    education = st.selectbox("Niveau d'√©ducation", options=["primary", "secondary", "tertiary"])
    balance = st.number_input("Solde du compte bancaire", value=0.0)
    housing = st.radio("Poss√®de un pr√™t immobilier ?", options=["Oui", "Non"])
    day = st.number_input("Jour du contact", min_value=1, max_value=31, value=15)
    month = st.selectbox("Mois du contact", options=['jan', 'feb', 'mar', 'apr', 'may', 'jun', 'jul', 'aug', 'sep', 'oct', 'nov', 'dec'])
    duration = st.number_input("Dur√©e de l'appel (en secondes)", min_value=0, value=100)
    poutcome = st.radio("R√©sultat de la campagne pr√©c√©dente ?", options=["Success", "Failure", "missing"])
    pdays_contacted = st.radio("D√©j√† contact√© ?", options=["Oui", "Non"])
    campaign = st.selectbox("Nombre de contacts durant cette campagne", options=["1 fois", "2 fois", "3-6 fois", "> 6 fois"])

    # Mapping des variables cat√©goriques
    education_mapping = {"primary": 0, "secondary": 1, "tertiary": 2}
    month_mapping = {'jan': 1, 'feb': 2, 'mar': 3, 'apr': 4, 'may': 5, 'jun': 6,
                     'jul': 7, 'aug': 8, 'sep': 9, 'oct': 10, 'nov': 11, 'dec': 12}
    
    education = education_mapping[education]
    housing = 1 if housing == "Oui" else 0
    pdays_contacted = 1 if pdays_contacted == "Oui" else 0
    month = month_mapping[month]

    # Cr√©ation du DataFrame utilisateur
    user_data = pd.DataFrame([[age, education, balance, housing, day, month, duration, pdays_contacted, campaign, poutcome]],
                             columns=['age', 'education', 'balance', 'housing', 'day', 'month', 'duration', 'pdays_contacted', 'campaign', 'poutcome'])

    # One-Hot Encoding
    one_hot_cols = ['campaign', 'poutcome']
    encoder = OneHotEncoder(drop='first', sparse_output=False, handle_unknown='ignore')

    encoded_data = encoder.fit_transform(user_data[one_hot_cols])
    encoded_df = pd.DataFrame(encoded_data, columns=encoder.get_feature_names_out(one_hot_cols))
    user_data = pd.concat([user_data.drop(columns=one_hot_cols), encoded_df], axis=1)

    # Chargement du mod√®le et du scaler depuis GitHub
    try:
        main_dir = "https://raw.githubusercontent.com/Manal-art-coder/DataScientest_Project/main/"
        model_url = main_dir + "final_model.pkl"
        scaler_url = main_dir + "scaler.pkl"

        # T√©l√©charger le mod√®le
        response = requests.get(model_url)
        response.raise_for_status()
        model = joblib.load(BytesIO(response.content))

        # Ajouter les colonnes manquantes
        expected_columns = model.feature_names_in_
        for col in expected_columns:
            if col not in user_data.columns:
                user_data[col] = 0
        user_data = user_data[expected_columns]

        # T√©l√©charger et appliquer le scaler
        response = requests.get(scaler_url)
        response.raise_for_status()
        scaler = joblib.load(BytesIO(response.content))

        numerical_columns = ['age', 'balance', 'day', 'duration']
        existing_numerical_columns = [col for col in numerical_columns if col in user_data.columns]
        user_data[existing_numerical_columns] = scaler.transform(user_data[existing_numerical_columns])

        # Pr√©diction
        if st.button("üîç Pr√©dire"):
            prediction = model.predict(user_data)[0]
            st.write("üîÆ Pr√©diction brute :", prediction)
            result = "‚úÖ Le client VA souscrire" if prediction == 1 else "‚ùå Le client NE souscrira PAS"
            st.success(result)

    except Exception as e:
        st.error(f"‚ùå Erreur : {e}")

    # üì• Upload de fichier CSV
    uploaded_file = st.file_uploader("üì• T√©l√©chargez votre fichier CSV", type=["csv"])

    if uploaded_file is not None:
        user_data = pd.read_csv(uploaded_file)
        st.write("‚úÖ Donn√©es charg√©es avec succ√®s !")

        # Traitement des valeurs inconnues
        user_data.replace(["unknown", "Unknown", "UNKNOWN", "other", "Other", "OTHER"], np.nan, inplace=True)
        if 'pdays' in user_data.columns:
            user_data['pdays_contacted'] = (user_data['pdays'] != -1).astype(int)

        # Suppression de colonnes inutiles
        columns_to_drop = ['default', 'contact', 'previous', 'pdays']
        user_data.drop(columns=[col for col in columns_to_drop if col in user_data.columns], inplace=True)

        # Encodage et transformation
        categorical_imputer = SimpleImputer(strategy='most_frequent')
        one_hot_cols = ['job', 'marital', 'poutcome', 'campaign']
        encoder = OneHotEncoder(drop='first', sparse_output=False, handle_unknown='ignore')

        if all(col in user_data.columns for col in one_hot_cols):
            encoded_data = encoder.fit_transform(user_data[one_hot_cols])
            encoded_df = pd.DataFrame(encoded_data, columns=encoder.get_feature_names_out(one_hot_cols))
            user_data = pd.concat([user_data.drop(columns=one_hot_cols), encoded_df], axis=1)

        numerical_columns = ['age', 'balance', 'day', 'duration']
        scaler = RobustScaler()
        if all(col in user_data.columns for col in numerical_columns):
            user_data[numerical_columns] = scaler.fit_transform(user_data[numerical_columns])

        st.write("üìä Donn√©es apr√®s pr√©traitement :")
        st.dataframe(user_data.head())

        # T√©l√©chargement des donn√©es transform√©es
        csv_buffer = io.BytesIO()
        user_data.to_csv(csv_buffer, index=False)
        csv_buffer.seek(0)
        st.download_button(label="üì• T√©l√©charger les donn√©es pr√©trait√©es", data=csv_buffer, file_name="transformed_data.csv", mime="text/csv")

        # Pr√©diction sur les donn√©es charg√©es
        try:
            prediction = model.predict(user_data)
            user_data["Pr√©diction"] = ["Souscrit ‚úÖ" if p == 1 else "Ne souscrit pas ‚ùå" for p in prediction]
            st.dataframe(user_data)

        except Exception as e:
            st.error(f"‚ùå Erreur lors de la pr√©diction : {e}")

if page == pages[7]:
    st.write("## üìä Conclusion & Recommandations")

    st.write("### üîé R√©sum√© des r√©sultats")
    st.write("""
    Notre mod√®le final a confirm√© plusieurs tendances observ√©es lors de la phase d'exploration des donn√©es :
    - **Dur√©e du dernier contact üìû** : Tr√®s corr√©l√©e avec la souscription, mais probl√©matique pour une pr√©diction en amont.
    - **P√©riode des campagnes üìÖ** : Mai est inefficace, alors que septembre et octobre sont plus favorables.
    - **Ciblage par √¢ge üë•** : Les jeunes (-25 ans) et les seniors (+65 ans) souscrivent davantage.
    - **Jours de contact optimaux üìÜ** : mardi, mercredi et jeudi offrent les meilleurs taux de conversion.
    - **Solde du compte üí∞** : Plus il est √©lev√©, plus la souscription est probable.
    - **Impact des pr√™ts üè¶** : Les clients avec un pr√™t immobilier sont moins enclins √† souscrire √† un DAT.
    """)

    st.write("### üìå Recommandations strat√©giques")
    st.markdown("""
    üîπ **Optimisation des campagnes**  
    - Cibler les campagnes en septembre/octobre plut√¥t qu'en mai.  
    - Planifier les appels principalement en milieu de semaine.  
      
    üîπ **Am√©lioration du ciblage client**  
    - Segmenter les clients en fonction de leur solde bancaire.  
    - Privil√©gier les profils ayant r√©pondu positivement √† des campagnes pr√©c√©dentes.  
      
    üîπ **Strat√©gie d‚Äôengagement client**  
    - Former les √©quipes pour prolonger la dur√©e des appels et am√©liorer le taux de conversion.  
    - Personnaliser les offres en fonction des besoins sp√©cifiques des tranches d‚Äô√¢ge.  
    """)

if page ==pages[8]:
    st.write("## üöÄ Difficult√©s rencontr√©es & Perspectives")
    st.write("""
    üîπ **Utilisation de la variable duration**  
    - Variable informative mais inutilisable en amont.  
    - Son retrait a diminu√© les performances du mod√®le.  
      
    üîπ **Mod√©lisation et choix des algorithmes**  
    - Test de plusieurs mod√®les avant d‚Äôidentifier le meilleur.  
    - Difficult√© √† choisir entre pr√©diction avant ou apr√®s le premier contact.  
      
    üîπ **Probl√®mes de donn√©es**  
    - Valeurs inconnues dans certaines variables (`poutcome`, `education`).  
    - D√©s√©quilibre des campagnes pass√©es compliquant l'analyse des r√©sultats.  
    """)

    st.write("### üéØ Bilan et r√©sultats obtenus")
    st.markdown("""
    - **Mod√®le final** : Pr√©cision **85%** et F1-score **0.83**.  
    - **Benchmark** : R√©sultats comp√©titifs par rapport aux standards du secteur bancaire.  
    - **Impact business** : Am√©lioration de l‚Äôefficacit√© des campagnes marketing.  
    """)

    st.write("### üîç Pistes d‚Äôam√©lioration")
    st.markdown("""
    ‚úÖ **Am√©liorer les variables** en cr√©ant de nouvelles interactions (√¢ge & statut pro, solde & pr√™t).   
    ‚úÖ **Tester l‚Äôutilisation de duration** en la pr√©disant dans un mod√®le s√©par√©.  
    ‚úÖ **Test A/B** pour valider les recommandations sur un √©chantillon r√©el.  
    """)
    st.success("Ce projet nous a permis d'explorer des probl√©matiques r√©elles de Machine Learning appliqu√©es au marketing bancaire et de mieux comprendre l'importance des variables temporelles dans la pr√©diction.")



      

      
        
      


    



        


